import streamlit as st
import requests
from bs4 import BeautifulSoup
import jieba
import re
from collections import Counter
import pandas as pd
from pyecharts.charts import WordCloud, Bar, Line, Pie, Radar, Scatter, Funnel, Gauge
from pyecharts import options as opts
from pyecharts.globals import ThemeType
from streamlit_echarts import st_pyecharts  # Streamlité›†æˆpyecharts

# ---------------------- 1. å…¨å±€é…ç½® ----------------------
# é¡µé¢åŸºç¡€è®¾ç½®
st.set_page_config(
    page_title="URLæ–‡ç« åˆ†è¯å¯è§†åŒ–å·¥å…·",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åŠ è½½åœç”¨è¯è¡¨
def load_stopwords():
    """åŠ è½½åœç”¨è¯ï¼ˆä¼˜å…ˆæœ¬åœ°æ–‡ä»¶ï¼Œæ— åˆ™ç”¨é»˜è®¤é›†åˆï¼‰"""
    default_stopwords = {
        "çš„", "äº†", "æ˜¯", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬", "åœ¨", "å’Œ", "ä¸", "æˆ–",
        "å°±", "éƒ½", "è€Œ", "åŠ", "å³", "ä¹Ÿ", "åˆ", "è¿˜", "å› ", "ä¸º", "ä»¥", "äº", "ä¹‹",
        "è¿™", "é‚£", "æ­¤", "å½¼", "ä¸ª", "äº›", "èƒ½", "å¯", "ä¼š", "åº”", "è¦", "å°†", "æŠŠ",
        "å¯¹", "å¯¹äº", "å…³äº", "é€šè¿‡", "éšç€", "æŒ‰ç…§", "åŸºäº", "æ ¹æ®", "å¦‚æœ", "å‡å¦‚"
    }
    try:
        with open("stopwords.txt", "r", encoding="utf-8") as f:
            return set([line.strip() for line in f if line.strip()])
    except FileNotFoundError:
        st.warning("æœªæ‰¾åˆ°åœç”¨è¯æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤åœç”¨è¯è¡¨")
        return default_stopwords

STOPWORDS = load_stopwords()

# ---------------------- 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ----------------------
def crawl_url_article(url: str) -> tuple:
    """çˆ¬å–URLæ–‡ç« æ­£æ–‡"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        response.encoding = response.apparent_encoding  # è‡ªåŠ¨è¯†åˆ«ç¼–ç 
        soup = BeautifulSoup(response.text, "html.parser")
        
        # ç§»é™¤æ— å…³æ ‡ç­¾
        for tag in soup(["script", "style", "nav", "footer", "aside", "header"]):
            tag.decompose()
        
        # æå–æ­£æ–‡ï¼ˆé€‚é…æ–°é—»/åšå®¢é¡µé¢ï¼‰
        content_tags = soup.find_all("article") or soup.find_all("div", class_=lambda x: x and ("content" in x.lower() or "article" in x.lower())) or soup.find_all("p")
        article_text = "\n".join([tag.get_text().strip() for tag in content_tags if tag.get_text().strip()])
        
        if not article_text:
            return None, "æœªæå–åˆ°æ­£æ–‡ï¼ˆå¯èƒ½æ˜¯åŠ¨æ€é¡µé¢/æ ‡ç­¾ä¸åŒ¹é…ï¼‰"
        return article_text, ""
    except Exception as e:
        return None, f"çˆ¬å–å¤±è´¥ï¼š{str(e)}"

def clean_and_segment(text: str) -> tuple:
    """æ–‡æœ¬æ¸…æ´—+åˆ†è¯+è¯é¢‘ç»Ÿè®¡"""
    # æ¸…æ´—æ–‡æœ¬
    text = re.sub(r"<[^>]+>", "", text)  # ç§»é™¤HTMLæ ‡ç­¾
    text = re.sub(r"[0-9a-zA-Z\s+]", "", text)  # ç§»é™¤æ•°å­—/å­—æ¯/å¤šä½™ç©ºæ ¼
    text = re.sub(r"[^\u4e00-\u9fa5ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€ï¼ˆï¼‰ã€ã€‘]", "", text)  # ä»…ä¿ç•™ä¸­æ–‡
    
    # åˆ†è¯+è¿‡æ»¤åœç”¨è¯/å•å­—
    seg_list = jieba.lcut(text)
    seg_list = [word for word in seg_list if word not in STOPWORDS and len(word) > 1 and word.strip()]
    
    # è¯é¢‘ç»Ÿè®¡
    word_count = Counter(seg_list)
    return seg_list, word_count

def filter_low_freq_words(word_count: Counter, min_freq: int) -> Counter:
    """è¿‡æ»¤ä½é¢‘è¯"""
    return Counter({word: count for word, count in word_count.items() if count >= min_freq})

# ---------------------- 3. å›¾è¡¨ç”Ÿæˆå‡½æ•° ----------------------
def generate_chart(chart_type: str, word_data: list):
    """æ ¹æ®é€‰æ‹©çš„å›¾è¡¨ç±»å‹ç”ŸæˆPyechartså›¾è¡¨"""
    # å–TOP20æ•°æ®
    top20_data = word_data[:20]
    words = [item[0] for item in top20_data]
    counts = [item[1] for item in top20_data]
    
    if chart_type == "è¯äº‘":
        c = (
            WordCloud(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="100%", height="600px"))
            .add("", top20_data, word_size_range=[20, 100])
            .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘TOP20è¯äº‘å›¾", subtitle="è¿‡æ»¤ä½é¢‘è¯å"))
        )
    elif chart_type == "æŸ±çŠ¶å›¾":
        c = (
            Bar(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="100%", height="600px"))
            .add_xaxis(words)
            .add_yaxis("è¯é¢‘", counts)
            .reversal_axis()  # æ¨ªå‘æŸ±çŠ¶å›¾ï¼ˆé€‚é…é•¿æ–‡æœ¬ï¼‰
            .set_global_opts(
                title_opts=opts.TitleOpts(title="è¯é¢‘TOP20æŸ±çŠ¶å›¾"),
                xaxis_opts=opts.AxisOpts(name="è¯é¢‘"),
                yaxis_opts=opts.AxisOpts(name="è¯æ±‡")
            )
        )
    elif chart_type == "æŠ˜çº¿å›¾":
        c = (
            Line(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="100%", height="600px"))
            .add_xaxis(words)
            .add_yaxis("è¯é¢‘", counts, markpoint_opts=opts.MarkPointOpts(data=[opts.MarkPointItem(type_="max"), opts.MarkPointItem(type_="min")]))
            .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘TOP20æŠ˜çº¿å›¾"))
        )
    elif chart_type == "é¥¼å›¾":
        c = (
            Pie(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="100%", height="600px"))
            .add("", top20_data)
            .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘TOP20é¥¼å›¾"), legend_opts=opts.LegendOpts(orient="vertical", pos_top="10%", pos_left="80%"))
            .set_series_opts(label_opts=opts.LabelOpts(formatter="{b}: {c}"))
        )
    elif chart_type == "é›·è¾¾å›¾":
        c = (
            Radar(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="100%", height="600px"))
            .add_schema(schema=[opts.RadarIndicatorItem(name=word, max_=max(counts)) for word in words[:10]])  # ä»…å±•ç¤ºå‰10ä¸ªï¼ˆé¿å…é›·è¾¾å›¾è¿‡å¯†ï¼‰
            .add("è¯é¢‘", [counts[:10]])
            .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘TOP10é›·è¾¾å›¾"))
        )
    elif chart_type == "æ•£ç‚¹å›¾":
        c = (
            Scatter(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="100%", height="600px"))
            .add_xaxis(words)
            .add_yaxis("è¯é¢‘", counts)
            .set_global_opts(
                title_opts=opts.TitleOpts(title="è¯é¢‘TOP20æ•£ç‚¹å›¾"),
                xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=45)),
                yaxis_opts=opts.AxisOpts(name="è¯é¢‘")
            )
        )
    elif chart_type == "æ¼æ–—å›¾":
        c = (
            Funnel(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="100%", height="600px"))
            .add("", top20_data)
            .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘TOP20æ¼æ–—å›¾"))
            .set_series_opts(label_opts=opts.LabelOpts(formatter="{b}: {c}"))
        )
    elif chart_type == "ä»ªè¡¨ç›˜":
        # ä»ªè¡¨ç›˜å±•ç¤ºTOP1è¯æ±‡çš„è¯é¢‘ï¼ˆé€‚é…å•å€¼å±•ç¤ºï¼‰
        top1_word, top1_count = top20_data[0] if top20_data else ("æ— æ•°æ®", 0)
        c = (
            Gauge(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="100%", height="600px"))
            .add(f"è¯é¢‘", [(top1_word, top1_count)])
            .set_global_opts(
                title_opts=opts.TitleOpts(title=f"é«˜é¢‘è¯TOP1ï¼š{top1_word}"),
                legend_opts=opts.LegendOpts(is_show=False)
            )
        )
    return c

# ---------------------- 4. Streamlité¡µé¢å¸ƒå±€ ----------------------
def main():
    st.title("ğŸ“ URLæ–‡ç« åˆ†è¯å¯è§†åŒ–åˆ†æå·¥å…·")
    st.markdown("---")

    # å·¦ä¾§è¾¹æ ï¼ˆå›¾è¡¨ç­›é€‰+å‚æ•°é…ç½®ï¼‰
    with st.sidebar:
        st.header("ğŸ”§ å›¾è¡¨ç­›é€‰ä¸é…ç½®")
        # å›¾è¡¨ç±»å‹é€‰æ‹©ï¼ˆè‡³å°‘7ç§ï¼‰
        chart_type = st.selectbox(
            "é€‰æ‹©å›¾è¡¨ç±»å‹",
            ["è¯äº‘", "æŸ±çŠ¶å›¾", "æŠ˜çº¿å›¾", "é¥¼å›¾", "é›·è¾¾å›¾", "æ•£ç‚¹å›¾", "æ¼æ–—å›¾", "ä»ªè¡¨ç›˜"],
            index=0
        )
        # ä½é¢‘è¯è¿‡æ»¤é˜ˆå€¼
        min_freq = st.slider(
            "è¿‡æ»¤ä½é¢‘è¯ï¼ˆæœ€å°å‡ºç°æ¬¡æ•°ï¼‰",
            min_value=1,
            max_value=20,
            value=2,
            step=1,
            help="ä»…å±•ç¤ºå‡ºç°æ¬¡æ•°â‰¥è¯¥å€¼çš„è¯æ±‡"
        )
        st.markdown("---")
        st.info("ğŸ’¡ æ“ä½œè¯´æ˜ï¼šè¾“å…¥URLâ†’çˆ¬å–æ–‡ç« â†’è‡ªåŠ¨åˆ†è¯â†’é€‰æ‹©å›¾è¡¨ç±»å‹æŸ¥çœ‹ç»“æœ")

    # ä¸»é¡µé¢ï¼šURLè¾“å…¥+çˆ¬å–
    col1, col2 = st.columns([3, 1])
    with col1:
        url = st.text_input("ğŸ“Œ è¾“å…¥æ–‡ç« URL", placeholder="ä¾‹å¦‚ï¼šhttps://www.ithome.com/0/780/123.htm")
    with col2:
        crawl_btn = st.button("ğŸš€ çˆ¬å–å¹¶åˆ†æ", type="primary")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼ˆä¿å­˜è¯é¢‘æ•°æ®ï¼Œé¿å…é‡å¤çˆ¬å–ï¼‰
    if "word_count" not in st.session_state:
        st.session_state.word_count = Counter()

    # çˆ¬å–+åˆ†æé€»è¾‘
    if crawl_btn and url:
        with st.spinner("æ­£åœ¨çˆ¬å–æ–‡ç« å¹¶åˆ†æ..."):
            # 1. çˆ¬å–æ–‡ç« 
            article_text, error = crawl_url_article(url)
            if error:
                st.error(error)
                return
            st.success(f"âœ… æ–‡ç« çˆ¬å–æˆåŠŸï¼åŸå§‹æ­£æ–‡é•¿åº¦ï¼š{len(article_text)} å­—")

            # 2. æ¸…æ´—åˆ†è¯+è¯é¢‘ç»Ÿè®¡
            seg_list, word_count = clean_and_segment(article_text)
            st.session_state.word_count = word_count
            st.info(f"ğŸ“Š åˆ†è¯å®Œæˆï¼æœ‰æ•ˆåˆ†è¯æ•°ï¼š{len(seg_list)} | å”¯ä¸€è¯æ±‡æ•°ï¼š{len(word_count)}")

    # å±•ç¤ºç»“æœï¼ˆæœ‰è¯é¢‘æ•°æ®æ—¶ï¼‰
    if st.session_state.word_count:
        st.markdown("---")
        # è¿‡æ»¤ä½é¢‘è¯
        filtered_word_count = filter_low_freq_words(st.session_state.word_count, min_freq)
        if not filtered_word_count:
            st.warning(f"âš ï¸ è¿‡æ»¤åæ— æ•°æ®ï¼ˆæœ€å°è¯é¢‘è®¾ä¸º{min_freq}ï¼Œå¯é™ä½é˜ˆå€¼é‡è¯•ï¼‰")
            return
        
        # æ’åºå–TOP20
        sorted_word_data = filtered_word_count.most_common(20)
        
        # å±•ç¤ºè¯é¢‘TOP20è¡¨æ ¼
        st.subheader("ğŸ“ˆ è¯é¢‘æ’åTOP20ï¼ˆè¿‡æ»¤ä½é¢‘è¯åï¼‰")
        top20_df = pd.DataFrame(sorted_word_data, columns=["è¯æ±‡", "å‡ºç°æ¬¡æ•°"])
        st.dataframe(top20_df, use_container_width=True)

        # ç”Ÿæˆå¹¶å±•ç¤ºå›¾è¡¨
        st.subheader(f"ğŸ¨ {chart_type}å±•ç¤º")
        chart = generate_chart(chart_type, sorted_word_data)
        st_pyecharts(chart, key=chart_type)  # keyç¡®ä¿åˆ‡æ¢å›¾è¡¨æ—¶é‡æ–°æ¸²æŸ“

if __name__ == "__main__":
    main()